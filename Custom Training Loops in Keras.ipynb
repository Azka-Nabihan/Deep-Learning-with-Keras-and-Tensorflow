{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e87970",
   "metadata": {},
   "source": [
    "# Custom Training Loops in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b799abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "# Suppress all Python warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set TensorFlow log level to suppress warnings and info messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Step 1: Set Up the Environment\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() \n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcaad5c",
   "metadata": {},
   "source": [
    "## Define The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a490dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71152a0d",
   "metadata": {},
   "source": [
    "## Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ece9b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) \n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef0f02f",
   "metadata": {},
   "source": [
    "## Implement the Custom Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de272566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 1\n",
      "Epoch 1 Step 0: Loss = 2.327298641204834\n",
      "Epoch 1 Step 200: Loss = 0.36879265308380127\n",
      "Epoch 1 Step 400: Loss = 0.20166833698749542\n",
      "Epoch 1 Step 600: Loss = 0.12539997696876526\n",
      "Epoch 1 Step 800: Loss = 0.13895612955093384\n",
      "Epoch 1 Step 1000: Loss = 0.444985568523407\n",
      "Epoch 1 Step 1200: Loss = 0.17133165895938873\n",
      "Epoch 1 Step 1400: Loss = 0.2113090455532074\n",
      "Epoch 1 Step 1600: Loss = 0.21189343929290771\n",
      "Epoch 1 Step 1800: Loss = 0.19413301348686218\n",
      "Start of epoch 2\n",
      "Epoch 2 Step 0: Loss = 0.09056811034679413\n",
      "Epoch 2 Step 200: Loss = 0.14047843217849731\n",
      "Epoch 2 Step 400: Loss = 0.11003763228654861\n",
      "Epoch 2 Step 600: Loss = 0.048787884414196014\n",
      "Epoch 2 Step 800: Loss = 0.0851454883813858\n",
      "Epoch 2 Step 1000: Loss = 0.267480731010437\n",
      "Epoch 2 Step 1200: Loss = 0.10105648636817932\n",
      "Epoch 2 Step 1400: Loss = 0.12533798813819885\n",
      "Epoch 2 Step 1600: Loss = 0.14928655326366425\n",
      "Epoch 2 Step 1800: Loss = 0.1257006973028183\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "# train_dataset = train_dataset.repeat(epochs)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "for epoch in range(epochs):\n",
    "    print(f'Start of epoch {epoch + 1}')\n",
    "\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)  # Forward pass\n",
    "            loss_value = loss_fn(y_batch_train, logits)  # Compute loss\n",
    "\n",
    "        # Compute gradients\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        # Update weights\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # Logging the loss every 200 steps\n",
    "        if step % 200 == 0:\n",
    "            print(f'Epoch {epoch + 1} Step {step}: Loss = {loss_value.numpy()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703b530e",
   "metadata": {},
   "source": [
    "## Define Loss Function and Optimizer (Add accuracy metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8701e5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)  \n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8271fce",
   "metadata": {},
   "source": [
    "## Implement the custom training loop with accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "448e4292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of eopch 1\n",
      "Epoch 1 Step 0: Loss = 0.018028568476438522, Accuracy = 0.9752465486526489\n",
      "Epoch 1 Step 200: Loss = 0.07714109122753143, Accuracy = 0.9760657548904419\n",
      "Epoch 1 Step 400: Loss = 0.06679058074951172, Accuracy = 0.9763702750205994\n",
      "Epoch 1 Step 600: Loss = 0.044337447732686996, Accuracy = 0.9768780469894409\n",
      "Epoch 1 Step 800: Loss = 0.029298681765794754, Accuracy = 0.9773098826408386\n",
      "Epoch 1 Step 1000: Loss = 0.1106564849615097, Accuracy = 0.9778012037277222\n",
      "Epoch 1 Step 1200: Loss = 0.04148627072572708, Accuracy = 0.9780965447425842\n",
      "Epoch 1 Step 1400: Loss = 0.03512387350201607, Accuracy = 0.9784131050109863\n",
      "Epoch 1 Step 1600: Loss = 0.05119360610842705, Accuracy = 0.978621244430542\n",
      "Epoch 1 Step 1800: Loss = 0.04453087970614433, Accuracy = 0.9789513349533081\n",
      "Start of eopch 2\n",
      "Epoch 2 Step 0: Loss = 0.014405915513634682, Accuracy = 1.0\n",
      "Epoch 2 Step 200: Loss = 0.06961792707443237, Accuracy = 0.9875621795654297\n",
      "Epoch 2 Step 400: Loss = 0.03687578812241554, Accuracy = 0.9872194528579712\n",
      "Epoch 2 Step 600: Loss = 0.047135572880506516, Accuracy = 0.9876247644424438\n",
      "Epoch 2 Step 800: Loss = 0.01360141858458519, Accuracy = 0.9873595237731934\n",
      "Epoch 2 Step 1000: Loss = 0.11100098490715027, Accuracy = 0.9876685738563538\n",
      "Epoch 2 Step 1200: Loss = 0.03754999116063118, Accuracy = 0.987406313419342\n",
      "Epoch 2 Step 1400: Loss = 0.01979895308613777, Accuracy = 0.9873973727226257\n",
      "Epoch 2 Step 1600: Loss = 0.04413454979658127, Accuracy = 0.9874492287635803\n",
      "Epoch 2 Step 1800: Loss = 0.02808109112083912, Accuracy = 0.9876110553741455\n",
      "Start of eopch 3\n",
      "Epoch 3 Step 0: Loss = 0.005698238965123892, Accuracy = 1.0\n",
      "Epoch 3 Step 200: Loss = 0.038435403257608414, Accuracy = 0.9906716346740723\n",
      "Epoch 3 Step 400: Loss = 0.02508828043937683, Accuracy = 0.9902587532997131\n",
      "Epoch 3 Step 600: Loss = 0.04649297893047333, Accuracy = 0.9911605715751648\n",
      "Epoch 3 Step 800: Loss = 0.02052903361618519, Accuracy = 0.9912609457969666\n",
      "Epoch 3 Step 1000: Loss = 0.1037006601691246, Accuracy = 0.9914772510528564\n",
      "Epoch 3 Step 1200: Loss = 0.022918688133358955, Accuracy = 0.9913613796234131\n",
      "Epoch 3 Step 1400: Loss = 0.009178203530609608, Accuracy = 0.9912116527557373\n",
      "Epoch 3 Step 1600: Loss = 0.022120967507362366, Accuracy = 0.9911578893661499\n",
      "Epoch 3 Step 1800: Loss = 0.014411426149308681, Accuracy = 0.9911160469055176\n",
      "Start of eopch 4\n",
      "Epoch 4 Step 0: Loss = 0.0036126889754086733, Accuracy = 1.0\n",
      "Epoch 4 Step 200: Loss = 0.023065395653247833, Accuracy = 0.9931591749191284\n",
      "Epoch 4 Step 400: Loss = 0.0259547121822834, Accuracy = 0.9932200908660889\n",
      "Epoch 4 Step 600: Loss = 0.03004695475101471, Accuracy = 0.9942803382873535\n",
      "Epoch 4 Step 800: Loss = 0.014914912171661854, Accuracy = 0.9940699338912964\n",
      "Epoch 4 Step 1000: Loss = 0.06958238035440445, Accuracy = 0.9942869544029236\n",
      "Epoch 4 Step 1200: Loss = 0.008544553071260452, Accuracy = 0.9942756295204163\n",
      "Epoch 4 Step 1400: Loss = 0.012059434317052364, Accuracy = 0.9940221309661865\n",
      "Epoch 4 Step 1600: Loss = 0.01610264927148819, Accuracy = 0.9938514828681946\n",
      "Epoch 4 Step 1800: Loss = 0.007195040117949247, Accuracy = 0.993927001953125\n",
      "Start of eopch 5\n",
      "Epoch 5 Step 0: Loss = 0.0048740277998149395, Accuracy = 1.0\n",
      "Epoch 5 Step 200: Loss = 0.006312886252999306, Accuracy = 0.9948694109916687\n",
      "Epoch 5 Step 400: Loss = 0.01872224174439907, Accuracy = 0.9943890571594238\n",
      "Epoch 5 Step 600: Loss = 0.03802097216248512, Accuracy = 0.9952163100242615\n",
      "Epoch 5 Step 800: Loss = 0.012437520548701286, Accuracy = 0.9955524206161499\n",
      "Epoch 5 Step 1000: Loss = 0.0421779528260231, Accuracy = 0.9957854747772217\n",
      "Epoch 5 Step 1200: Loss = 0.00753395352512598, Accuracy = 0.9957327246665955\n",
      "Epoch 5 Step 1400: Loss = 0.005089967977255583, Accuracy = 0.9957842826843262\n",
      "Epoch 5 Step 1600: Loss = 0.020127424970269203, Accuracy = 0.9957448244094849\n",
      "Epoch 5 Step 1800: Loss = 0.004120822995901108, Accuracy = 0.9958009719848633\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Start of eopch {epoch + 1}')\n",
    "    \n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass : Compute predictions\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            # Compute loss\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "            \n",
    "        # Compute gradients\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        # Apply gradients to update model weights\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        # Update accuracy metric\n",
    "        accuracy_metric.update_state(y_batch_train, logits)\n",
    "        \n",
    "        # Log the loss and accuracy every 200 steps\n",
    "        if step % 200 == 0:\n",
    "            print(f'Epoch {epoch + 1} Step {step}: Loss = {loss_value.numpy()}, Accuracy = {accuracy_metric.result().numpy()}')\n",
    "            \n",
    "    # Reset accuracy metric at the end of each epoch\n",
    "    accuracy_metric.reset_state()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
